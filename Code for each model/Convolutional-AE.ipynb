{"cells":[{"cell_type":"markdown","source":["**In order to get the results, you need to run everything up to Model Training and Results Section, and then run all the code blocks with the face2sketch comment for the face2sketch training and results, and after getting the results, execute the sketch2face blocks for the sketch2face results.**"],"metadata":{"id":"zod3R6suuPMF"}},{"cell_type":"markdown","metadata":{"id":"UrJyqW46nBZh"},"source":["We start by importing the used libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"5x9MMvzcmfaI","executionInfo":{"status":"ok","timestamp":1645631431324,"user_tz":0,"elapsed":3056,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}}},"outputs":[],"source":["#https://www.kaggle.com/theblackmamba31/photo-to-sketch-using-autoencoder/notebook\n","import numpy as np\n","import tensorflow as tf\n","import keras \n","from keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Input\n","from keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import cv2\n","from tqdm import tqdm \n","import os\n","import re"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22247,"status":"ok","timestamp":1645631455749,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"},"user_tz":0},"id":"BSsmWwJtz4aL","outputId":"2a05c826-9712-4b35-be3f-9862c0e941ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["#https://drive.google.com/drive/folders/1C2lQ61MssBmVjRxrzYy0vqDOMWWxSEex?usp=sharing Get the files into your drive and open from there\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["def sorted_alphanumeric(data):  \n","    convert = lambda text: int(text) if text.isdigit() else text.lower()\n","    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n","    return sorted(data,key = alphanum_key)\n","\n","\n","# defining the size of image \n","SIZE = 256\n","\n","image_path = \"/content/gdrive/MyDrive/Data_for_CW1/photos\"\n","img_array = []\n","\n","sketch_path = '/content/gdrive/MyDrive/Data_for_CW1/sketches'\n","sketch_array = []\n","\n","\n","image_file = sorted_alphanumeric(os.listdir(image_path))\n","sketch_file = sorted_alphanumeric(os.listdir(sketch_path))"],"metadata":{"id":"qYKlnVtGYOqY","executionInfo":{"status":"ok","timestamp":1645631462828,"user_tz":0,"elapsed":2116,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dCUscrnZnHrU"},"source":["Load data.\n","\n","We convert the images to arrays ansd then we store them in a list\n","\n","Data augumentation is also performed due to the small amount of provided samples"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70508,"status":"ok","timestamp":1645631534165,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"},"user_tz":0},"id":"SWn8mBHhnObX","outputId":"29babbf0-d873-4abb-9227-242c92b0ca31"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 188/188 [00:03<00:00, 50.15it/s]\n","100%|██████████| 188/188 [01:06<00:00,  2.83it/s]\n"]}],"source":["for i in tqdm(image_file):\n","    image = cv2.imread(image_path + '/' + i,1)\n","    \n","    # as opencv load image in bgr format converting it to rgb\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    \n","    # resizing images \n","    image = cv2.resize(image, (SIZE, SIZE))\n","    \n","    # normalizing image \n","    image = image.astype('float32') / 255.0\n","    \n","    #appending normal normal image    \n","    img_array.append(img_to_array(image))\n","    # Image Augmentation\n","    \n","    # horizontal flip \n","    img1 = cv2.flip(image,1)\n","    img_array.append(img_to_array(img1))\n","     #vertical flip \n","    img2 = cv2.flip(image,-1)\n","    img_array.append(img_to_array(img2))\n","     #vertical flip \n","    img3 = cv2.flip(image,-1)\n","    # horizontal flip\n","    img3 = cv2.flip(img3,1)\n","    img_array.append(img_to_array(img3))\n","    # rotate clockwise \n","    img4 = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n","    img_array.append(img_to_array(img4))\n","    # flip rotated image \n","    img5 = cv2.flip(img4,1)\n","    img_array.append(img_to_array(img5))\n","     # rotate anti clockwise \n","    img6 = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n","    img_array.append(img_to_array(img6))\n","    # flip rotated image \n","    img7 = cv2.flip(img6,1)\n","    img_array.append(img_to_array(img7))\n","  \n","    \n","for i in tqdm(sketch_file):\n","    image = cv2.imread(sketch_path + '/' + i,1)\n","    \n","    # as opencv load image in bgr format converting it to rgb\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    \n","    # resizing images \n","    image = cv2.resize(image, (SIZE, SIZE))\n","    \n","    # normalizing image \n","    image = image.astype('float32') / 255.0\n","    # appending normal sketch image\n","    sketch_array.append(img_to_array(image))\n","    \n","    #Image Augmentation\n","    # horizontal flip \n","    img1 = cv2.flip(image,1)\n","    sketch_array.append(img_to_array(img1))\n","     #vertical flip \n","    img2 = cv2.flip(image,-1)\n","    sketch_array.append(img_to_array(img2))\n","     #vertical flip \n","    img3 = cv2.flip(image,-1)\n","    # horizontal flip\n","    img3 = cv2.flip(img3,1)\n","    sketch_array.append(img_to_array(img3))\n","    # rotate clockwise \n","    img4 = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n","    sketch_array.append(img_to_array(img4))\n","    # flip rotated image \n","    img5 = cv2.flip(img4,1)\n","    sketch_array.append(img_to_array(img5))\n","     # rotate anti clockwise \n","    img6 = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n","    sketch_array.append(img_to_array(img6))\n","    # flip rotated image \n","    img7 = cv2.flip(img6,1)\n","    sketch_array.append(img_to_array(img7))"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227,"status":"ok","timestamp":1645631536211,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"},"user_tz":0},"id":"jrfKsMKc3-wJ","outputId":"be7c7a58-4335-4c29-c3dd-a8d9fc97cb11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of sketch images: 1504\n","Total number of images: 1504\n","256\n"]}],"source":["print(\"Total number of sketch images:\",len(sketch_array))\n","print(\"Total number of images:\",len(img_array))\n","print(len(img_array[1]))"]},{"cell_type":"markdown","metadata":{"id":"IdmhEZqm5bI0"},"source":["Slicing and reshaping\n","\n","Out of 1504 images I have sliced them to two part. train images consist 1400 images while test images contains 104 images. After slicing image array, I reshaped them so that images can be fed directly into our encoder network"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":901,"status":"ok","timestamp":1645631538290,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"},"user_tz":0},"id":"Ynyu_Zcu5dda","outputId":"1dfab3f6-f246-447a-dafe-c90c32364a5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train color image shape: (1400, 256, 256, 3)\n","Test color image shape (104, 256, 256, 3)\n"]}],"source":["train_sketch_image = sketch_array[:1400]\n","train_image = img_array[:1400]\n","test_sketch_image = sketch_array[1400:]\n","test_image = img_array[1400:]\n","# reshaping\n","train_sketch_image = np.reshape(train_sketch_image,(len(train_sketch_image),SIZE,SIZE,3))\n","train_image = np.reshape(train_image, (len(train_image),SIZE,SIZE,3))\n","print('Train color image shape:',train_image.shape)\n","test_sketch_image = np.reshape(test_sketch_image,(len(test_sketch_image),SIZE,SIZE,3))\n","test_image = np.reshape(test_image, (len(test_image),SIZE,SIZE,3))\n","print('Test color image shape',test_image.shape)"]},{"cell_type":"code","source":["#Load the model if you dont want to run the process again\n","from tensorflow.keras.models import load_model\n","model = load_model('/content/gdrive/MyDrive/Data_for_CW1/MyModels/Conv_AE/sketch2faceConvAE.h5')"],"metadata":{"id":"wG_yiDi8Rrwa","executionInfo":{"status":"ok","timestamp":1645631892569,"user_tz":0,"elapsed":2178,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1BkQaE05519F"},"source":["**Downsample layer**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DAi4NZzA53tG"},"outputs":[],"source":["def downsample(filters, size, apply_batch_normalization = True):\n","    downsample = tf.keras.models.Sequential()\n","    downsample.add(keras.layers.Conv2D(filters = filters, kernel_size = size, strides = 2, use_bias = False, kernel_initializer = 'he_normal'))\n","    if apply_batch_normalization:\n","        downsample.add(keras.layers.BatchNormalization())\n","    downsample.add(keras.layers.LeakyReLU())\n","    return downsample"]},{"cell_type":"markdown","metadata":{"id":"BxqyL62u55an"},"source":["**Upsample Layer**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xpX0MyCv58iH"},"outputs":[],"source":["def upsample(filters, size, apply_dropout = False):\n","    upsample = tf.keras.models.Sequential()\n","    upsample.add(keras.layers.Conv2DTranspose(filters = filters, kernel_size = size, strides = 2, use_bias = False, kernel_initializer = 'he_normal'))\n","    if apply_dropout:\n","        upsample.add(tf.keras.layers.Dropout(0.1))\n","    upsample.add(tf.keras.layers.LeakyReLU()) \n","    return upsample"]},{"cell_type":"markdown","metadata":{"id":"UDvBf8d_6Aiu"},"source":["**Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aNjjOIfB5_QX"},"outputs":[],"source":["def model():\n","    encoder_input = keras.Input(shape = (SIZE, SIZE, 3))\n","    x = downsample(16, 4, False)(encoder_input)\n","    x = downsample(32,4)(x)\n","    x = downsample(64,4,False)(x)\n","    x = downsample(128,4)(x)\n","    x = downsample(256,4)(x)\n","   \n","    encoder_output = downsample(512,4)(x)\n","    \n","    decoder_input = upsample(512,4,True)(encoder_output)\n","    x = upsample(256,4,False)(decoder_input)\n","    x = upsample(128,4, True)(x)\n","    x = upsample(64,4)(x)\n","    x = upsample(32,4)(x)\n","    x = upsample(16,4)(x)\n","    x = tf.keras.layers.Conv2DTranspose(8,(2,2),strides = (1,1), padding = 'valid')(x)\n","    decoder_output = tf.keras.layers.Conv2DTranspose(3,(2,2),strides = (1,1), padding = 'valid')(x)\n","    \n","  \n","    return tf.keras.Model(encoder_input, decoder_output)"]},{"cell_type":"markdown","metadata":{"id":"wVH_IiBd6IXQ"},"source":["To get summary of model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7KRmSepF6KY5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645466519646,"user_tz":0,"elapsed":3237,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivGFB_tw1nvABLpPYAgqp_h0v3vI5IcGqU0kan=s64","userId":"02346670573850784711"}},"outputId":"1ba30a69-96f1-490b-c80e-af19ee8e4ca6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n","                                                                 \n"," sequential (Sequential)     (None, 127, 127, 16)      768       \n","                                                                 \n"," sequential_1 (Sequential)   (None, 62, 62, 32)        8320      \n","                                                                 \n"," sequential_2 (Sequential)   (None, 30, 30, 64)        32768     \n","                                                                 \n"," sequential_3 (Sequential)   (None, 14, 14, 128)       131584    \n","                                                                 \n"," sequential_4 (Sequential)   (None, 6, 6, 256)         525312    \n","                                                                 \n"," sequential_5 (Sequential)   (None, 2, 2, 512)         2099200   \n","                                                                 \n"," sequential_6 (Sequential)   (None, 6, 6, 512)         4194304   \n","                                                                 \n"," sequential_7 (Sequential)   (None, 14, 14, 256)       2097152   \n","                                                                 \n"," sequential_8 (Sequential)   (None, 30, 30, 128)       524288    \n","                                                                 \n"," sequential_9 (Sequential)   (None, 62, 62, 64)        131072    \n","                                                                 \n"," sequential_10 (Sequential)  (None, 126, 126, 32)      32768     \n","                                                                 \n"," sequential_11 (Sequential)  (None, 254, 254, 16)      8192      \n","                                                                 \n"," conv2d_transpose_6 (Conv2DT  (None, 255, 255, 8)      520       \n"," ranspose)                                                       \n","                                                                 \n"," conv2d_transpose_7 (Conv2DT  (None, 256, 256, 3)      99        \n"," ranspose)                                                       \n","                                                                 \n","=================================================================\n","Total params: 9,786,347\n","Trainable params: 9,784,491\n","Non-trainable params: 1,856\n","_________________________________________________________________\n"]}],"source":["model = model()\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"xEAY_mkh6Uz1"},"source":["Compiling and Fitting our model\n","\n","Here i have used Adam optimizer and mean_squared_error as loss and have trained model for 100 epochs"]},{"cell_type":"markdown","source":["# Model Training and Results"],"metadata":{"id":"A0ncQCQauD4W"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"FQ9qPwSP6WhH"},"outputs":[],"source":["#face2sketch\n","model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n","              metrics = ['acc'])\n","\n","hist = model.fit(train_image, train_sketch_image, epochs = 100, verbose = 1)\n","\n","plt.plot(hist.history[\"loss\"]);\n","plt.xlabel('Epochs');\n","plt.ylabel('Training Error');"]},{"cell_type":"code","source":["#sketch2face\n","model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n","              metrics = ['acc'])\n","\n","hist2 = model.fit(train_sketch_image, train_image, epochs = 100, verbose = 1)\n","\n","plt.plot(hist2.history[\"loss\"]);\n","plt.xlabel('Epochs');\n","plt.ylabel('Training Error');"],"metadata":{"id":"M8TCncPLzIb7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluating our face2sketch model"],"metadata":{"id":"VJqbvgfuMFCw"}},{"cell_type":"code","source":["#face2sketch\n","prediction_on_test_data = model.evaluate(test_image, test_sketch_image)\n","print(\"Loss: \", prediction_on_test_data[0])\n","print(\"Accuracy: \", np.round(prediction_on_test_data[1] * 100,1))"],"metadata":{"id":"9-r2n-J3ziIS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645631591551,"user_tz":0,"elapsed":9649,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}},"outputId":"46258946-edbd-41bd-acce-286d4df6f8a0"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 9s 60ms/step - loss: 0.0771 - acc: 0.3530\n","Loss:  0.07714570313692093\n","Accuracy:  35.3\n"]}]},{"cell_type":"markdown","metadata":{"id":"7UT4ORsY6bf4"},"source":["Evaluating our sketch2face model"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":875,"status":"ok","timestamp":1645631905260,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"},"user_tz":0},"id":"AJcXcrJI6cBG","outputId":"dac557c9-3303-4d5f-818a-f77f7c432bc0"},"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 0s 32ms/step - loss: 0.0784 - acc: 0.8972\n","Loss:  0.07843179255723953\n","Accuracy:  89.7\n"]}],"source":["#sketch2face\n","prediction_on_test_data = model.evaluate(test_sketch_image, test_image)\n","print(\"Loss: \", prediction_on_test_data[0])\n","print(\"Accuracy: \", np.round(prediction_on_test_data[1] * 100,1))"]},{"cell_type":"markdown","metadata":{"id":"m_Hnga8q6fjn"},"source":["Plotting our predicted sketch along with real sketch"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"1z8U5NZi6gD7","executionInfo":{"status":"ok","timestamp":1645631596883,"user_tz":0,"elapsed":247,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}}},"outputs":[],"source":["#face2sketch\n","def show_images(real,sketch, predicted):\n","    plt.figure(figsize = (12,12))\n","    plt.subplot(1,3,1)\n","    plt.title(\"Image\",fontsize = 15, color = 'Lime')\n","    plt.imshow(real)\n","    plt.subplot(1,3,2)\n","    plt.title(\"sketch\",fontsize = 15, color = 'Blue')\n","    plt.imshow(sketch)\n","    plt.subplot(1,3,3)\n","    plt.title(\"Predicted\",fontsize = 15, color = 'gold')\n","    plt.imshow(predicted)"]},{"cell_type":"code","source":["#sketch2face\n","def show_images2(sketch, real, predicted):\n","    plt.figure(figsize = (12,12))\n","    plt.subplot(1,3,1)\n","    plt.title(\"Sketch\",fontsize = 15, color = 'Lime')\n","    plt.imshow(sketch)\n","    plt.subplot(1,3,2)\n","    plt.title(\"Image\",fontsize = 15, color = 'Blue')\n","    plt.imshow(real)\n","    plt.subplot(1,3,3)\n","    plt.title(\"Predicted\",fontsize = 15, color = 'gold')\n","    plt.imshow(predicted)"],"metadata":{"id":"Uj13WzGv0K5I","executionInfo":{"status":"ok","timestamp":1645631908245,"user_tz":0,"elapsed":204,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0YQ0g3I06hWW"},"outputs":[],"source":["#face2sketch\n","ls = [i for i in range(0,95,8)]\n","for i in ls:\n","    predicted =np.clip(model.predict(test_image[i].reshape(1,SIZE,SIZE,3)),0.0,1.0).reshape(SIZE,SIZE,3)\n","    show_images(test_image[i],test_sketch_image[i],predicted)"]},{"cell_type":"code","source":["#sketch2face\n","ls = [i for i in range(0,95,8)]\n","for i in ls:\n","    predicted =np.clip(model.predict(test_sketch_image[i].reshape(1,SIZE,SIZE,3)),0.0,1.0).reshape(SIZE,SIZE,3)\n","    show_images2(test_sketch_image[i],test_image[i],predicted)"],"metadata":{"id":"odIDxaUCz1vZ","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1MNzGSDzEb1DiEUlDCHNiOCwD49KNsnXE"},"executionInfo":{"status":"ok","timestamp":1645631921666,"user_tz":0,"elapsed":9096,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}},"outputId":"17ba0ad5-12db-4a48-95aa-fd0c3a494781"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["#face2sketch\n","pred = []\n","for i in range(0,104):\n","  predicted =np.clip(model.predict(test_image[i].reshape(1,SIZE,SIZE,3)),0.0,1.0).reshape(SIZE,SIZE,3)\n","  pred.append(predicted)"],"metadata":{"id":"04I9fvx5S2NV","executionInfo":{"status":"ok","timestamp":1645631793144,"user_tz":0,"elapsed":5559,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["#sketch2face\n","pred = []\n","for i in range(0,104):\n","  predicted =np.clip(model.predict(test_sketch_image[i].reshape(1,SIZE,SIZE,3)),0.0,1.0).reshape(SIZE,SIZE,3)\n","  pred.append(predicted)"],"metadata":{"id":"vRpQ4TbJS4Px","executionInfo":{"status":"ok","timestamp":1645631926681,"user_tz":0,"elapsed":5026,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["from skimage.metrics import structural_similarity as ssim1\n","SSIMarray = []\n","sumssim = 0\n","for i in range(0, 104):\n","  SSIM = ssim1(test_image[i], pred[i], multichannel=True)\n","  SSIMarray.append(SSIM)\n","  sumssim+= SSIM\n","\n","avgssim = sumssim/104\n","print(\"SSIM =\",avgssim)\n","\n","from sklearn.metrics import mean_squared_error as mse1\n","import math\n","RMSEarray = []\n","sumrmse = 0\n","\n","t = np.reshape(test_image, (104,-1))\n","p = np.reshape(pred, (104,-1))\n","\n","for i in range(0, 104):\n","  MSE = mse1(t[i], p[i])\n","  RMSEarray.append(math.sqrt(MSE))\n","  sumrmse+= math.sqrt(MSE)\n","\n","avgrmse = sumrmse/104\n","print(\"RMSE =\",avgrmse)\n","\n","from sklearn.metrics import median_absolute_error as mae\n","\n","maearray = []\n","summae = 0\n","\n","for i in range(0, 104):\n","  MAE = mae(t[i], p[i])\n","  maearray.append(MAE)\n","  summae+= MAE\n","\n","avgrmae = summae/104\n","print(\"MAE =\",avgrmae)\n","\n"],"metadata":{"id":"biwAf2yhngIJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645631933063,"user_tz":0,"elapsed":3950,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}},"outputId":"570a9656-4097-41e9-cde6-29a01b07887a"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["SSIM = 0.8240065892981835\n","RMSE = 0.12190834309288986\n","MAE = 0.05104717565700412\n"]}]},{"cell_type":"markdown","source":["Save the models"],"metadata":{"id":"2lZZbG4JYzT6"}},{"cell_type":"code","source":["#face2sketch\n","#model.save('/content/gdrive/MyDrive/MyModels/Conv_AE/face2sketchConvAE.h5')"],"metadata":{"id":"w2fi18IPYy89"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#sketch2face\n","#model.save(\"/content/gdrive/MyDrive/MyModels/Conv_AE/sketch2faceConvAE.h5\")"],"metadata":{"id":"3IXZ3jbdYzD5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Paizei na kanei prin to architcture\n","#tf.keras.utils.plot_model(ae_encoder, show_shapes=True)"],"metadata":{"id":"H2YfIjfW_wF9"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"!ConvolutionalAECW1.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOLKaFohG0YYoP26iabYtFS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}