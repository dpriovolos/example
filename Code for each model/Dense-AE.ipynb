{"cells":[{"cell_type":"markdown","source":["**In order to get the results, you need to run everything up to Model Training and Results Section, and then run all the code blocks with the face2sketch comment for the face2sketch training and results, and after getting the results, execute the sketch2face blocks for the sketch2face results.**"],"metadata":{"id":"JLIYV9IrJlYy"}},{"cell_type":"markdown","metadata":{"id":"UrJyqW46nBZh"},"source":["We start by importing the used libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"5x9MMvzcmfaI","executionInfo":{"status":"ok","timestamp":1645630880873,"user_tz":0,"elapsed":2060,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}}},"outputs":[],"source":["#From the week 3 lab files, but a little tweked so in has more depth\n","import numpy as np\n","import tensorflow as tf\n","import keras \n","from keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D, Dropout, Input\n","from keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import cv2\n","from tqdm import tqdm \n","import os\n","import re"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18350,"status":"ok","timestamp":1645630920646,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"},"user_tz":0},"id":"BSsmWwJtz4aL","outputId":"1ac8c069-8d76-4f05-a1b4-0ea5db7c9261"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["#https://drive.google.com/drive/folders/1C2lQ61MssBmVjRxrzYy0vqDOMWWxSEex?usp=sharing Get the files into your drive and open from there\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["def sorted_alphanumeric(data):  \n","    convert = lambda text: int(text) if text.isdigit() else text.lower()\n","    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n","    return sorted(data,key = alphanum_key)\n","\n","\n","# defining the size of image \n","SIZE = 128\n","\n","image_path = \"/content/gdrive/MyDrive/Data_for_CW1/photos\"\n","img_array = []\n","\n","sketch_path = '/content/gdrive/MyDrive/Data_for_CW1/sketches'\n","sketch_array = []\n","\n","\n","image_file = sorted_alphanumeric(os.listdir(image_path))\n","sketch_file = sorted_alphanumeric(os.listdir(sketch_path))"],"metadata":{"id":"qYKlnVtGYOqY","executionInfo":{"status":"ok","timestamp":1645630925369,"user_tz":0,"elapsed":2702,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dCUscrnZnHrU"},"source":["Load data.\n","\n","We convert the images to arrays ansd then we store them in a list\n","\n","Data augumentation is also performed due to the small amount of provided samples"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":117966,"status":"ok","timestamp":1645631044384,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"},"user_tz":0},"id":"SWn8mBHhnObX","outputId":"650b2cb0-bb96-4df0-8a85-c6bf2258676c"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 188/188 [00:03<00:00, 50.51it/s] \n","100%|██████████| 188/188 [01:53<00:00,  1.65it/s]\n"]}],"source":["for i in tqdm(image_file):\n","    image = cv2.imread(image_path + '/' + i,1)\n","    \n","    # as opencv load image in bgr format converting it to rgb\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    \n","    # resizing images \n","    image = cv2.resize(image, (SIZE, SIZE))\n","    \n","    # normalizing image \n","    image = image.astype('float32') / 255.0\n","    \n","    #appending normal normal image    \n","    img_array.append(img_to_array(image))\n","    # Image Augmentation\n","    \n","    # horizontal flip \n","    img1 = cv2.flip(image,1)\n","    img_array.append(img_to_array(img1))\n","     #vertical flip \n","    img2 = cv2.flip(image,-1)\n","    img_array.append(img_to_array(img2))\n","     #vertical flip \n","    img3 = cv2.flip(image,-1)\n","    # horizontal flip\n","    img3 = cv2.flip(img3,1)\n","    img_array.append(img_to_array(img3))\n","    # rotate clockwise \n","    img4 = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n","    img_array.append(img_to_array(img4))\n","    # flip rotated image \n","    img5 = cv2.flip(img4,1)\n","    img_array.append(img_to_array(img5))\n","     # rotate anti clockwise \n","    img6 = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n","    img_array.append(img_to_array(img6))\n","    # flip rotated image \n","    img7 = cv2.flip(img6,1)\n","    img_array.append(img_to_array(img7))\n","  \n","    \n","for i in tqdm(sketch_file):\n","    image = cv2.imread(sketch_path + '/' + i,1)\n","    \n","    # as opencv load image in bgr format converting it to rgb\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    \n","    # resizing images \n","    image = cv2.resize(image, (SIZE, SIZE))\n","    \n","    # normalizing image \n","    image = image.astype('float32') / 255.0\n","    # appending normal sketch image\n","    sketch_array.append(img_to_array(image))\n","    \n","    #Image Augmentation\n","    # horizontal flip \n","    img1 = cv2.flip(image,1)\n","    sketch_array.append(img_to_array(img1))\n","     #vertical flip \n","    img2 = cv2.flip(image,-1)\n","    sketch_array.append(img_to_array(img2))\n","     #vertical flip \n","    img3 = cv2.flip(image,-1)\n","    # horizontal flip\n","    img3 = cv2.flip(img3,1)\n","    sketch_array.append(img_to_array(img3))\n","    # rotate clockwise \n","    img4 = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n","    sketch_array.append(img_to_array(img4))\n","    # flip rotated image \n","    img5 = cv2.flip(img4,1)\n","    sketch_array.append(img_to_array(img5))\n","     # rotate anti clockwise \n","    img6 = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n","    sketch_array.append(img_to_array(img6))\n","    # flip rotated image \n","    img7 = cv2.flip(img6,1)\n","    sketch_array.append(img_to_array(img7))"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":361,"status":"ok","timestamp":1645631050915,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"},"user_tz":0},"id":"jrfKsMKc3-wJ","outputId":"c1ace2b4-06da-43c3-efea-3ca9b5e41007"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total number of sketch images: 1504\n","Total number of images: 1504\n","128\n"]}],"source":["print(\"Total number of sketch images:\",len(sketch_array))\n","print(\"Total number of images:\",len(img_array))\n","print(len(img_array[1]))"]},{"cell_type":"markdown","metadata":{"id":"IdmhEZqm5bI0"},"source":["Slicing and reshaping\n","\n","Out of 1504 images I have sliced them to two part. train images consist 1400 images while test images contains 104 images. After slicing image array, I reshaped them so that images can be fed directly into our encoder network"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1645631052213,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"},"user_tz":0},"id":"Ynyu_Zcu5dda","outputId":"6a3820b8-c703-403a-aea2-c4963715c31d"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1400, 128, 128, 3)\n","(1400, 128, 128, 3)\n","(104, 128, 128, 3)\n","(104, 128, 128, 3)\n"]}],"source":["train_sketch_image = sketch_array[:1400]\n","train_image = img_array[:1400]\n","test_sketch_image = sketch_array[1400:]\n","test_image = img_array[1400:]\n","\n","train_sketch_image = np.array(train_sketch_image)\n","train_image = np.array(train_image)\n","test_sketch_image = np.array(test_sketch_image)\n","test_image = np.array(test_image)\n","\n","\n","print(train_sketch_image.shape)\n","print(train_image.shape)\n","print(test_sketch_image.shape)\n","print(test_image.shape)"]},{"cell_type":"code","source":["# reshaping\n","train_sketch_image = train_sketch_image.reshape((len(train_sketch_image), np.prod(train_sketch_image.shape[1:])))\n","train_image = train_image.reshape((len(train_image), np.prod(train_image.shape[1:])))\n","print('Train color image shape:',train_image.shape)\n","test_sketch_image = test_sketch_image.reshape((len(test_sketch_image), np.prod(test_sketch_image.shape[1:])))\n","test_image = test_image.reshape((len(test_image), np.prod(test_image.shape[1:])))\n","print('Test color image shape',test_image.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GF1DDwotbvyg","executionInfo":{"status":"ok","timestamp":1645631053529,"user_tz":0,"elapsed":3,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}},"outputId":"617798ca-d87b-4d42-e27d-35ac401940cd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Train color image shape: (1400, 49152)\n","Test color image shape (104, 49152)\n"]}]},{"cell_type":"code","source":["np.shape(test_sketch_image)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZJi5cd8NpbZV","executionInfo":{"status":"ok","timestamp":1645463867297,"user_tz":0,"elapsed":4,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivGFB_tw1nvABLpPYAgqp_h0v3vI5IcGqU0kan=s64","userId":"02346670573850784711"}},"outputId":"7cf629b9-f002-4bfc-9feb-3f8d2ca45dc1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(104, 49152)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["#Load the model if you dont want to run the process again\n","from tensorflow.keras.models import load_model\n","model = load_model('/content/gdrive/MyDrive/Data_for_CW1/MyModels/DAE/sketch2faceDAE.h5')"],"metadata":{"id":"2IXbhqeY6bWT","executionInfo":{"status":"ok","timestamp":1645631126922,"user_tz":0,"elapsed":63877,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UDvBf8d_6Aiu"},"source":["**Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aNjjOIfB5_QX"},"outputs":[],"source":["# define a 8x8 deep autoencoder\n","input_img = keras.Input(shape=(49152,))\n","encoded = keras.layers.Dense(4096, activation='relu')(input_img)\n","encoded = keras.layers.Dense(2048, activation='relu')(encoded)\n","encoded = keras.layers.Dense(1024, activation='relu')(encoded)\n","encoded = keras.layers.Dense(512, activation='relu')(encoded)\n","encoded = keras.layers.Dense(256, activation='relu')(encoded)\n","encoded = keras.layers.Dense(128, activation='relu')(encoded)\n","encoded = keras.layers.Dense(64, activation='relu')(encoded)\n","encoded = keras.layers.Dense(32, activation='relu')(encoded)\n","\n","decoded = keras.layers.Dense(64, activation='relu')(encoded)\n","decoded = keras.layers.Dense(128, activation='relu')(decoded)\n","decoded = keras.layers.Dense(256, activation='relu')(decoded)\n","decoded = keras.layers.Dense(512, activation='relu')(decoded)\n","decoded = keras.layers.Dense(1024, activation='relu')(decoded)\n","decoded = keras.layers.Dense(2048, activation='relu')(decoded)\n","decoded = keras.layers.Dense(4096, activation='relu')(decoded)\n","decoded = keras.layers.Dense(49152, activation='sigmoid')(decoded)\n","\n","model = keras.Model(input_img, decoded)\n"]},{"cell_type":"markdown","metadata":{"id":"wVH_IiBd6IXQ"},"source":["To get summary of model\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"7KRmSepF6KY5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645625509394,"user_tz":0,"elapsed":409,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}},"outputId":"43a62ca6-9eb8-4759-878f-3f3d0b102f6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 49152)]           0         \n","                                                                 \n"," dense (Dense)               (None, 4096)              201330688 \n","                                                                 \n"," dense_1 (Dense)             (None, 2048)              8390656   \n","                                                                 \n"," dense_2 (Dense)             (None, 1024)              2098176   \n","                                                                 \n"," dense_3 (Dense)             (None, 512)               524800    \n","                                                                 \n"," dense_4 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_5 (Dense)             (None, 128)               32896     \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_7 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_8 (Dense)             (None, 64)                2112      \n","                                                                 \n"," dense_9 (Dense)             (None, 128)               8320      \n","                                                                 \n"," dense_10 (Dense)            (None, 256)               33024     \n","                                                                 \n"," dense_11 (Dense)            (None, 512)               131584    \n","                                                                 \n"," dense_12 (Dense)            (None, 1024)              525312    \n","                                                                 \n"," dense_13 (Dense)            (None, 2048)              2099200   \n","                                                                 \n"," dense_14 (Dense)            (None, 4096)              8392704   \n","                                                                 \n"," dense_15 (Dense)            (None, 49152)             201375744 \n","                                                                 \n","=================================================================\n","Total params: 425,086,880\n","Trainable params: 425,086,880\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"markdown","source":["# Model Training and Results"],"metadata":{"id":"5d68n32bLaOC"}},{"cell_type":"markdown","metadata":{"id":"xEAY_mkh6Uz1"},"source":["Compiling and Fitting our model\n","\n","Here i have used Adam optimizer and mean_absolute_error as loss and have trained model for 100 epochs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FQ9qPwSP6WhH"},"outputs":[],"source":["#Face2sketch\n","model.compile(optimizer='adam', loss='mean_squared_error', metrics = ['acc'])\n","\n","hist = model.fit(train_image, train_sketch_image,epochs=100, verbose = 1)\n","\n","plt.plot(hist.history[\"loss\"]);\n","plt.xlabel('Epochs');\n","plt.ylabel('Training Error');"]},{"cell_type":"markdown","metadata":{"id":"HD_3z8S_MWD5"},"source":["Evaluating our face2sketch model"]},{"cell_type":"code","source":["#face2sketch\n","prediction_on_test_data = model.evaluate(test_image, test_sketch_image)\n","print(\"Loss: \", prediction_on_test_data[0])\n","print(\"Accuracy: \", np.round(prediction_on_test_data[0] * 100,1))"],"metadata":{"id":"9-r2n-J3ziIS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645625519544,"user_tz":0,"elapsed":4038,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}},"outputId":"f73350d6-779e-4eda-b883-1b6055079320"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["4/4 [==============================] - 4s 31ms/step - loss: 0.0325 - acc: 0.0000e+00\n","Loss:  0.03245147317647934\n","Accuracy:  3.2\n"]}]},{"cell_type":"code","source":["#sketch2face\n","model.compile(optimizer='adam', loss='mean_squared_error', metrics = ['acc'])\n","\n","hist = model.fit(train_sketch_image, train_image, epochs=100,verbose = 1)\n","\n","plt.plot(hist.history[\"loss\"]);\n","plt.xlabel('Epochs');\n","plt.ylabel('Training Error');"],"metadata":{"id":"M8TCncPLzIb7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7UT4ORsY6bf4"},"source":["Evaluating our sketch2face model"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"AJcXcrJI6cBG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645631150162,"user_tz":0,"elapsed":2876,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}},"outputId":"ee973914-3844-4d56-c2eb-509905805a47"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train color image shape: (1400, 49152)\n","Test color image shape (104, 49152)\n","4/4 [==============================] - 2s 22ms/step - loss: 0.0196 - acc: 0.0000e+00\n","Loss:  0.01958073116838932\n","Accuracy:  0.0\n"]}],"source":["#sketch2face\n","#If you run it after the face2sketch training the dimentions change for the evaluation so we change it back\n","train_sketch_image = train_sketch_image.reshape((len(train_sketch_image), np.prod(train_sketch_image.shape[1:])))\n","train_image = train_image.reshape((len(train_image), np.prod(train_image.shape[1:])))\n","print('Train color image shape:',train_image.shape)\n","test_sketch_image = test_sketch_image.reshape((len(test_sketch_image), np.prod(test_sketch_image.shape[1:])))\n","test_image = test_image.reshape((len(test_image), np.prod(test_image.shape[1:])))\n","print('Test color image shape',test_image.shape)\n","\n","prediction_on_test_data = model.evaluate(test_sketch_image, test_image)\n","print(\"Loss: \", prediction_on_test_data[0])\n","print(\"Accuracy: \", np.round(prediction_on_test_data[1] * 100,1))"]},{"cell_type":"markdown","metadata":{"id":"m_Hnga8q6fjn"},"source":["Plotting our predicted sketch along with real sketch"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"1z8U5NZi6gD7","executionInfo":{"status":"ok","timestamp":1645625547146,"user_tz":0,"elapsed":841,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}}},"outputs":[],"source":["#face2sketch\n","encoded_imgs = model.predict(test_image)"]},{"cell_type":"code","source":["#sketch2face\n","encoded_imgs2 = model.predict(test_sketch_image)"],"metadata":{"id":"yUVKNP1hq-HX","executionInfo":{"status":"ok","timestamp":1645631153956,"user_tz":0,"elapsed":353,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#face2sketch\n","def show_images(real,sketch, predicted):\n","    plt.figure(figsize = (12,12))\n","    plt.subplot(1,3,1)\n","    plt.title(\"Image\",fontsize = 15, color = 'Lime')\n","    plt.imshow(real)\n","    plt.subplot(1,3,2)\n","    plt.title(\"Sketch\",fontsize = 15, color = 'Blue')\n","    plt.imshow(sketch)\n","    plt.subplot(1,3,3)\n","    plt.title(\"Predicted\",fontsize = 15, color = 'gold')\n","    plt.imshow(predicted)"],"metadata":{"id":"P3lm61T-pJat","executionInfo":{"status":"ok","timestamp":1645626338947,"user_tz":0,"elapsed":501,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["#sketch2face\n","def show_images2(real,image, predicted):\n","    plt.figure(figsize = (12,12))\n","    plt.subplot(1,3,1)\n","    plt.title(\"Sketch\",fontsize = 15, color = 'Lime')\n","    plt.imshow(real)\n","    plt.subplot(1,3,2)\n","    plt.title(\"Image\",fontsize = 15, color = 'Blue')\n","    plt.imshow(image)\n","    plt.subplot(1,3,3)\n","    plt.title(\"Predicted\",fontsize = 15, color = 'gold')\n","    plt.imshow(predicted)"],"metadata":{"id":"LHvhPIA1K760","executionInfo":{"status":"ok","timestamp":1645631156090,"user_tz":0,"elapsed":4,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#face2sketch and sketch2face (run for both models)\n","test_sketch_image = test_sketch_image.reshape(104, 128, 128, 3)\n","test_image = test_image.reshape(104, 128, 128, 3)\n","np.shape(test_sketch_image[1])\n"],"metadata":{"id":"7AGkmMlitCyx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645631158934,"user_tz":0,"elapsed":402,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}},"outputId":"d3277614-4937-45b0-ec11-d584bba7cdce"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(128, 128, 3)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["#face2sketch\n","ls = [i for i in range(0,95,8)]\n","pred1 = []\n","for i in ls:\n","    predicted =np.clip(encoded_imgs[i].reshape(SIZE,SIZE,3),0.0,1.0)\n","    pred1.append(predicted)\n","    test_sketch_image[i] = test_sketch_image[i].reshape(128, 128, 3)\n","    test_image[i] = test_image[i].reshape(128, 128, 3)\n","    show_images(test_image[i],test_sketch_image[i],predicted)"],"metadata":{"id":"NRktz9n7sZPK","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1qXwIYwLOfVsf7UmKVi2_7b7n4VYECqSR"},"executionInfo":{"status":"ok","timestamp":1645629429091,"user_tz":0,"elapsed":11621,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}},"outputId":"1bedc8f7-776d-4ea8-d0d5-9d565c1fc4f5"},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["#!pip install image-similarity-measures\n","#encoded_imgs1 or 2 depending on face2sketch or the opposite\n","pred1 = []\n","for i in range(0,104):\n","    predicted =np.clip(encoded_imgs2[i].reshape(SIZE,SIZE,3),0.0,1.0)\n","    pred1.append(predicted)"],"metadata":{"id":"sQJpvmKw8RAj","executionInfo":{"status":"ok","timestamp":1645631190519,"user_tz":0,"elapsed":343,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from skimage.metrics import structural_similarity as ssim1\n","SSIMarray = []\n","sumssim = 0\n","for i in range(0, 104):\n","  SSIM = ssim1(test_image[i], pred1[i], multichannel=True)\n","  SSIMarray.append(SSIM)\n","  sumssim+= SSIM\n","\n","avgssim = sumssim/104\n","print(\"SSIM =\",avgssim)\n","\n","from sklearn.metrics import mean_squared_error as mse1\n","import math\n","RMSEarray = []\n","sumrmse = 0\n","\n","t = np.reshape(test_image, (104,-1))\n","p = np.reshape(pred1, (104,-1))\n","\n","for i in range(0, 104):\n","  MSE = mse1(t[i], p[i])\n","  RMSEarray.append(math.sqrt(MSE))\n","  sumrmse+= math.sqrt(MSE)\n","\n","avgrmse = sumrmse/104\n","print(\"RMSE =\",avgrmse)\n","\n","from sklearn.metrics import median_absolute_error as mae\n","\n","maearray = []\n","summae = 0\n","\n","for i in range(0, 104):\n","  MAE = mae(t[i], p[i])\n","  maearray.append(MAE)\n","  summae+= MAE\n","\n","avgrmae = summae/104\n","print(\"MAE =\",avgrmae)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDLCehp1AJNv","executionInfo":{"status":"ok","timestamp":1645631198050,"user_tz":0,"elapsed":866,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}},"outputId":"a1841de0-972b-4fd6-a3f5-4e5e820003dc"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["SSIM = 0.7350823430964094\n","RMSE = 0.1361550913388706\n","MAE = 0.06467520169770488\n"]}]},{"cell_type":"code","source":["#sketch2face\n","ls = [i for i in range(0,95,8)]\n","pred2 = []\n","for i in ls:\n","    predicted =np.clip(encoded_imgs2[i].reshape(SIZE,SIZE,3),0.0,1.0)\n","    pred2.append(predicted)\n","    test_sketch_image[i] = test_sketch_image[i].reshape(128, 128, 3)\n","    test_image[i] = test_image[i].reshape(128, 128, 3)\n","    show_images2(test_sketch_image[i],test_image[i],predicted)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1g4Ue7kA6soMdHM8A0UFVB5xvPQ0iQOKP"},"id":"zNWzOrf_MsAQ","executionInfo":{"status":"ok","timestamp":1645631221492,"user_tz":0,"elapsed":11887,"user":{"displayName":"Dimitrios Priovolos","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhCmIugYar-fEj8MMNMsPAD0kZ1AW5Qc55nTJB1-w=s64","userId":"02346670573850784711"}},"outputId":"17616581-708c-4f60-b8ee-5fabba386235"},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["Save Models for reproducibility"],"metadata":{"id":"5EUhurC1NzB7"}},{"cell_type":"code","source":["#face2sketch\n","#model.save('/content/gdrive/MyDrive/MyModels/DAE/face2sketchDAE.h5')"],"metadata":{"id":"jmVNfuj1Nyo9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#sketch2face\n","#model.save(\"/content/gdrive/MyDrive/MyModels/DAE/sketch2faceDAE.h5\")"],"metadata":{"id":"FrRIDasSOGvk"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"!DenseAECW1.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyPOH08FdzcF+Zb+Kpa++2Im"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}